Hand2Text is a wearable device that translates American Sign Language (ASL) gestures into readable text displayed on an OLED screen. It is designed to assist deaf or hard-of-hearing individuals in communicating more easily with those unfamiliar with sign language.

ğŸ§  How It Works
Uses 5 flex sensors to detect finger bends.
Uses an MPU6050 accelerometer/gyroscope to detect hand orientation.
Processes sensor data with an STM32F401 microcontroller.
Recognized gestures are translated into characters and displayed on a 0.96" OLED screen via I2C.
âš™ï¸ Hardware Components
STM32F401 Microcontroller
5x Flex Sensors
1x MPU6050 Accelerometer + Gyroscope
1x OLED Display (I2C, 3.3V)
LiPo Battery + Buck-Boost Converter
Custom glove for mounting sensors
ğŸ› ï¸ Features
Real-time letter recognition from hand gestures
OLED display shows detected characters
Modular code structure for adding more gestures
Power-efficient wearable design
ğŸ“¦ Folder Structure
css
Copy
Edit
/Core                  â†’ STM32 source code  
/Drivers               â†’ Device drivers for sensors  
/Docs                  â†’ Diagrams, block diagrams, visuals  
/main.c                â†’ Main application file  
/README.md             â†’ This file  
ğŸ§ª Current Status
âœ… Prototype assembled
âœ… Initial gestures (A, B, C, P) working
ğŸ”§ Final testing and expansion of gesture set in progress
ğŸ“… Course Info
UC Davis â€” EEC 136AB Winter 2025
